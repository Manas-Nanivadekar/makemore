{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjTXj8K0SDO5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEbTgiy2X0dd",
        "outputId": "6ec51423-471f-4f80-b2cc-fe8e6ecd9033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-08 02:30:26--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt.1’\n",
            "\n",
            "\rnames.txt.1           0%[                    ]       0  --.-KB/s               \rnames.txt.1         100%[===================>] 222.80K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-06-08 02:30:26 (5.88 MB/s) - ‘names.txt.1’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('names.txt', 'r').read().splitlines()\n",
        "words[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX_R9S1USwt0",
        "outputId": "2cb19a8d-583f-4147-9ea6-aa5ac74f9a8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9ayUq7hS8BD",
        "outputId": "24eaa652-4372-4931-f5bb-3ba9b0764e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# building vocab of characters and mapping to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "print(itos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKZM7MAfS9QZ",
        "outputId": "23e9fd3e-d2b0-44b5-b50e-db564638a591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# building dataset\n",
        "\n",
        "block_size = 3\n",
        "X, Y = [], []\n",
        "\n",
        "for w in words:\n",
        "\n",
        "  # print(w)\n",
        "  context = [0] * block_size\n",
        "\n",
        "  for ch in w + '.':\n",
        "    ix = stoi[ch]\n",
        "    X.append(context)\n",
        "    Y.append(ix)\n",
        "    # print(''.join(itos[i] for i in context), '----->', itos[ix])\n",
        "    context = context[1:] + [ix]\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)"
      ],
      "metadata": {
        "id": "78y6wUcrTL3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, X.dtype, Y.shape, Y.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jc3lM2S9XX7F",
        "outputId": "bf8a6257-bf3c-4e3b-c913-85c9fcd2ef89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([228146, 3]), torch.int64, torch.Size([228146]), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C = torch.randn((27, 2))"
      ],
      "metadata": {
        "id": "9_HIKr2YXyIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[X]"
      ],
      "metadata": {
        "id": "l57pUPmPYsfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = torch.randn((6, 100))\n",
        "b1 = torch.randn(100)"
      ],
      "metadata": {
        "id": "rtq_sc59ZQZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)"
      ],
      "metadata": {
        "id": "S9RdOt40bFng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6Ys15HwbOj-",
        "outputId": "629d0248-d32b-427f-ddeb-b740a0844705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.0000, -0.7536,  0.9997,  ..., -0.9887, -0.1676,  0.6278],\n",
              "        [-0.9987, -0.1946,  0.7263,  ..., -0.9997, -0.9788,  0.3070],\n",
              "        [-0.9987, -0.9319,  0.9897,  ..., -0.9998, -0.9643, -0.7855],\n",
              "        ...,\n",
              "        [-0.9946, -0.9984, -0.9968,  ...,  1.0000, -0.9986,  0.9856],\n",
              "        [-0.3817,  1.0000, -1.0000,  ...,  0.3859, -0.9987,  0.5853],\n",
              "        [-0.5982, -0.9861,  0.9744,  ...,  0.4059, -0.8364, -0.9920]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W2 = torch.randn((100, 27))\n",
        "b2 = torch.randn(27)"
      ],
      "metadata": {
        "id": "5f3LDqdMbq_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = h @ W2 + b2"
      ],
      "metadata": {
        "id": "6_OFwnWPcC1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkKB6QB7cFZr",
        "outputId": "a2e312ed-c368-4c29-8216-8f661470cc1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([228146, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = logits.exp()"
      ],
      "metadata": {
        "id": "iAphBDclcHAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = counts / counts.sum(1, keepdim=True)"
      ],
      "metadata": {
        "id": "SQB87uFXcJRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "C = torch.randn((27,2), generator=g)\n",
        "W1 = torch.randn((6, 100), generator=g)\n",
        "b1 = torch.randn(100, generator=g)\n",
        "W2 = torch.randn((100, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]"
      ],
      "metadata": {
        "id": "lvRTaLdfdoDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.nelement() for p in parameters) # number of parameters in total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9m2W06Iebj8",
        "outputId": "b7bdd05c-0f02-4843-a182-4a11f7de722e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3481"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "counts = logits.exp()\n",
        "prob = counts / counts.sum(1, keepdim=True)\n",
        "loss = -prob[torch.arange(32), Y].log().mean()\n",
        "```\n",
        "Above code is same as Below\n",
        "\n",
        "```\n",
        "loss = F.cross_entropy(logits, Y)\n",
        "```\n",
        "\n",
        "Reasons to use this is, it reduces the need to create new Tensor, so less memory usage\n"
      ],
      "metadata": {
        "id": "BdQJZR2mWRJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "ctAdF5SIXowE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lre = torch.linspace(-3, 0, 1000)\n",
        "lrs = 10**lre"
      ],
      "metadata": {
        "id": "voL7z_4ccxqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lri = []\n",
        "lossi = []\n",
        "\n",
        "for i in range(10000):\n",
        "\n",
        "  #minibatch construct\n",
        "  ix = torch.randint(0, X.shape[0], (32,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[X[ix]] # (32, 3, 2)\n",
        "  h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Y[ix])\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  lr = 0.01\n",
        "  # update\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "\n",
        "  # track stats\n",
        "  # lri.append(lre[i])\n",
        "  # lossi.append(loss.item())\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "q_nR-9wcf4bo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd55e40-5262-4ec0-b69e-80e5c86ac702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.1015515327453613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training split, dev/val split, test split\n",
        "# 80%, 10%, 10%"
      ],
      "metadata": {
        "id": "kpqYOPp7dj-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building dataset\n",
        "\n",
        "def build_dataset(words):\n",
        "  block_size = 5\n",
        "  X, Y = [], []\n",
        "\n",
        "  for w in words:\n",
        "\n",
        "    # print(w)\n",
        "    context = [0] * block_size\n",
        "\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      # print(''.join(itos[i] for i in context), '----->', itos[ix])\n",
        "      context = context[1:] + [ix]\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  return X, Y\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr, Ytr = build_dataset(words[:n1])\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])\n",
        "Xte, Yte = build_dataset(words[n2:])"
      ],
      "metadata": {
        "id": "gTnVH292j0Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------Trainin NN on the training set----------------------------------"
      ],
      "metadata": {
        "id": "yyQWuZA0kgvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtr.shape, Ytr.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwGlQVyWk7SV",
        "outputId": "d78bfdcc-d691-4aaf-9e2f-b855323856fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([182625, 5]), torch.Size([182625]))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "C = torch.randn((27,20), generator=g)\n",
        "W1 = torch.randn((60, 400), generator=g)\n",
        "b1 = torch.randn(400, generator=g)\n",
        "W2 = torch.randn((400, 27), generator=g)\n",
        "b2 = torch.randn(27, generator=g)\n",
        "parameters = [C, W1, b1, W2, b2]"
      ],
      "metadata": {
        "id": "pgr1PvIJk92c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.nelement() for p in parameters) # number of parameters in total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUhrHwhFlGwV",
        "outputId": "e93cd47d-387e-47b3-eb11-7122daf53b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35767"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "dHyt00qulNhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lre = torch.linspace(-3, 0, 1000)\n",
        "lrs = 10**lre"
      ],
      "metadata": {
        "id": "gN1ZWRLBlQts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lri = []\n",
        "lossi = []\n",
        "stepi = []"
      ],
      "metadata": {
        "id": "kJE1QpsTpS-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(500000):\n",
        "\n",
        "  #minibatch construct\n",
        "  ix = torch.randint(0, Xtr.shape[0], (42,))\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xtr[ix]] # (32, 3, 2)\n",
        "  h = torch.tanh(emb.view(-1, 60) @ W1 + b1) # (32, 100)\n",
        "  logits = h @ W2 + b2 # (32, 27)\n",
        "  loss = F.cross_entropy(logits, Ytr[ix])\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  lr = 0.1 if i < 250000 else 0.01\n",
        "  # update\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "\n",
        "  # track stats\n",
        "  # lri.append(lre[i])\n",
        "  stepi.append(i)\n",
        "  lossi.append(loss.log10().item())\n",
        "\n",
        "# print(loss.item())"
      ],
      "metadata": {
        "id": "QcpawGFRlRcM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "11d39cbf-c95f-42a3-ca7b-d925977d896b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Expected input batch_size (70) to match target batch_size (42).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-b60a513dba9d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mW1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (32, 100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mW2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb2\u001b[0m \u001b[0;31m# (32, 27)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m# backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3493\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3494\u001b[0;31m     return torch._C._nn.cross_entropy_loss(\n\u001b[0m\u001b[1;32m   3495\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3496\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (70) to match target batch_size (42)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(stepi, lossi)"
      ],
      "metadata": {
        "id": "PbRqioGzpdqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[Xtr]\n",
        "h = torch.tanh(emb.view(-1, 60) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Ytr)\n",
        "loss"
      ],
      "metadata": {
        "id": "f4fDa_52pmaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[Xdev]\n",
        "h = torch.tanh(emb.view(-1, 60) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Ydev)\n",
        "loss"
      ],
      "metadata": {
        "id": "n5hYu5J_ld6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "plt.scatter(C[:, 0].data, C[:,1].data, s=500)\n",
        "for i in range(C.shape[0]):\n",
        "  plt.text(C[i, 0].item(), C[i,1].item(), itos[i], ha=\"center\", va=\"center\", color=\"white\")\n",
        "plt.grid('minor')"
      ],
      "metadata": {
        "id": "poXL8AUUmDsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample from the model\n",
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "      emb = C[torch.tensor([context])] # (1,block_size,d)\n",
        "      h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
        "      logits = h @ W2 + b2\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      if ix == 0:\n",
        "        break\n",
        "\n",
        "    print(''.join(itos[i] for i in out))"
      ],
      "metadata": {
        "id": "5YGkL8Z5opkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7jxXmJc7rQeV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}